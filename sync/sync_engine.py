"""
Advanced Synchronization Engine
===============================

This module provides robust bi-directional synchronization between PST files and 
Dynamics 365 CRM with intelligent conflict resolution, error recovery, and 
comprehensive monitoring capabilities.

Features:
- Bi-directional data synchronization
- Intelligent conflict detection and resolution
- Automatic error recovery and retry mechanisms
- Real-time monitoring and progress tracking
- Comprehensive audit logging
- Performance optimization

Author: AI Assistant
Version: 2.1
"""

import logging
import sqlite3
import json
import hashlib
import time
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import os
import threading
from pathlib import Path

# Setup module logger
logger = logging.getLogger(__name__)

# Import project modules
try:
    from exceptions import (
        SyncException, SyncConflictException, SyncValidationException,
        DatabaseException, PSTDynamicsException
    )
except ImportError:
    # Fallback for when running independently
    class SyncException(Exception):
        pass
    class SyncConflictException(SyncException):
        pass
    class SyncValidationException(SyncException):
        pass
    class DatabaseException(Exception):
        pass
    class PSTDynamicsException(Exception):
        pass


class ConflictResolutionStrategy(Enum):
    """
    Enumeration of available conflict resolution strategies.
    
    MANUAL: Require user intervention for all conflicts
    LAST_WRITE_WINS: Use the most recently modified version
    SOURCE_WINS: Always prefer source system data
    TARGET_WINS: Always prefer target system data
    MERGE: Attempt to intelligently merge conflicting data
    """
    MANUAL = "manual"
    LAST_WRITE_WINS = "last_write_wins"
    SOURCE_WINS = "source_wins"
    TARGET_WINS = "target_wins"
    MERGE = "merge"


class SyncStatus(Enum):
    """
    Enumeration of synchronization status values.
    """
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    PAUSED = "paused"


@dataclass
class SyncRecord:
    """
    Represents a single synchronization record with all metadata.
    """
    source_id: str
    target_id: Optional[str]
    record_type: str
    data: Dict[str, Any]
    checksum: str
    last_modified: datetime
    sync_status: SyncStatus = SyncStatus.PENDING
    conflict_data: Optional[Dict[str, Any]] = None
    retry_count: int = 0
    error_message: Optional[str] = None


@dataclass
class ConflictResolution:
    """
    Represents a conflict resolution decision.
    """
    conflict_id: str
    resolution_strategy: ConflictResolutionStrategy
    resolved_data: Dict[str, Any]
    resolution_timestamp: datetime
    user_decision: bool = False
    confidence_score: float = 0.0


@dataclass
class SyncMetrics:
    """
    Comprehensive synchronization metrics and statistics.
    """
    session_id: str
    start_time: datetime
    end_time: Optional[datetime] = None
    total_records: int = 0
    processed_records: int = 0
    successful_syncs: int = 0
    failed_syncs: int = 0
    conflicts_detected: int = 0
    conflicts_resolved: int = 0
    average_processing_time: float = 0.0
    throughput: float = 0.0
    error_rate: float = 0.0
    retry_count: int = 0


@dataclass
class SyncState:
    """
    Represents the synchronization state of an item.
    """
    item_id: str
    source_hash: str
    target_hash: str
    last_sync: datetime
    status: str = 'pending'


class RecoveryManager:
    """
    Manages error recovery and retry mechanisms.
    """
    
    def __init__(self, max_retries: int = 3, base_delay: float = 1.0):
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.circuit_breaker_threshold = 10
        self.circuit_breaker_timeout = 300
        self.failure_count = 0
        self.circuit_open_time = None
        self.logger = logging.getLogger(__name__)
    
    def execute_with_recovery(self, operation: Callable, *args, **kwargs) -> Any:
        if self._is_circuit_open():
            raise SyncException("Circuit breaker is open - system protection active")
        
        last_exception = None
        
        for attempt in range(self.max_retries + 1):
            try:
                result = operation(*args, **kwargs)
                self.failure_count = 0
                return result
                
            except (ConnectionError, TimeoutError, OSError) as e:
                # Network and connection related errors
                last_exception = e
                self.failure_count += 1
                
                if attempt < self.max_retries:
                    delay = self._calculate_delay(attempt)
                    self.logger.warning(f"Connection error (attempt {attempt + 1}/{self.max_retries + 1}), "
                                      f"retrying in {delay:.2f}s: {str(e)}")
                    time.sleep(delay)
                else:
                    self.logger.error(f"Connection failed after {self.max_retries + 1} attempts: {str(e)}")
            except (ValueError, TypeError, KeyError) as e:
                # Data validation and structure errors - don't retry
                self.logger.error(f"Data validation error, not retrying: {str(e)}")
                raise SyncValidationException(f"Data validation failed: {str(e)}")
            except DatabaseException as e:
                # Database specific errors
                last_exception = e
                self.failure_count += 1
                
                if attempt < self.max_retries:
                    delay = self._calculate_delay(attempt)
                    self.logger.warning(f"Database error (attempt {attempt + 1}/{self.max_retries + 1}), "
                                      f"retrying in {delay:.2f}s: {str(e)}")
                    time.sleep(delay)
                else:
                    self.logger.error(f"Database operation failed after {self.max_retries + 1} attempts: {str(e)}")
            except Exception as e:
                # Unexpected errors - log and don't retry
                self.logger.error(f"Unexpected error during operation: {str(e)}")
                raise SyncException(f"Unexpected error: {str(e)}")
        
        if self.failure_count >= self.circuit_breaker_threshold:
            self.circuit_open_time = datetime.now()
            self.logger.error("Circuit breaker opened due to excessive failures")
        
        raise SyncException(f"Operation failed after {self.max_retries + 1} attempts: {str(last_exception)}")
    
    def _calculate_delay(self, attempt: int) -> float:
        return self.base_delay * (2 ** attempt)
    
    def _is_circuit_open(self) -> bool:
        if self.circuit_open_time is None:
            return False
        
        if datetime.now() - self.circuit_open_time > timedelta(seconds=self.circuit_breaker_timeout):
            self.circuit_open_time = None
            self.failure_count = 0
            return False
        
        return True


class ConflictResolver:
    """
    Intelligent conflict resolution with multiple strategies.
    """
    
    def __init__(self, default_strategy: ConflictResolutionStrategy = ConflictResolutionStrategy.MANUAL):
        self.default_strategy = default_strategy
        self.resolution_history: List[ConflictResolution] = []
        self.logger = logging.getLogger(__name__)
    
    def detect_conflicts(self, source_data: Dict[str, Any], target_data: Dict[str, Any]) -> List[str]:
        conflicts = []
        
        for field, source_value in source_data.items():
            if field in target_data:
                target_value = target_data[field]
                if source_value != target_value and source_value is not None and target_value is not None:
                    if isinstance(source_value, str) and isinstance(target_value, str):
                        if source_value.strip() != target_value.strip():
                            conflicts.append(field)
                    elif self._normalize_value(source_value) != self._normalize_value(target_value):
                        conflicts.append(field)
        
        return conflicts
    
    def resolve_conflict(self, field_name: str, source_value: Any, target_value: Any, 
                        strategy: Optional[ConflictResolutionStrategy] = None) -> ConflictResolution:
        strategy = strategy or self.default_strategy
        conflict_id = hashlib.md5(f"{field_name}_{source_value}_{target_value}".encode()).hexdigest()
        
        resolution_data = {field_name: None}
        confidence_score = 0.0
        user_decision = False
        
        if strategy == ConflictResolutionStrategy.SOURCE_WINS:
            resolution_data[field_name] = source_value
            confidence_score = 1.0
            
        elif strategy == ConflictResolutionStrategy.TARGET_WINS:
            resolution_data[field_name] = target_value
            confidence_score = 1.0
            
        elif strategy == ConflictResolutionStrategy.LAST_WRITE_WINS:
            resolution_data[field_name] = source_value
            confidence_score = 0.8
            
        elif strategy == ConflictResolutionStrategy.MERGE:
            merged_value = self._merge_values(source_value, target_value)
            resolution_data[field_name] = merged_value
            confidence_score = 0.7
            
        elif strategy == ConflictResolutionStrategy.MANUAL:
            resolution_data[field_name] = source_value
            confidence_score = 0.0
            user_decision = True
        
        resolution = ConflictResolution(
            conflict_id=conflict_id,
            resolution_strategy=strategy,
            resolved_data=resolution_data,
            resolution_timestamp=datetime.now(),
            user_decision=user_decision,
            confidence_score=confidence_score
        )
        
        self.resolution_history.append(resolution)
        return resolution
    
    def resolve(self, conflict: Dict[str, Any], strategy: str = 'last_write_wins', user_choice: str = None) -> str:
        """Legacy method for backward compatibility"""
        field = conflict['change']['field']
        source_value = conflict['change']['source_value']
        target_value = conflict['change']['target_value']
        
        # Map string strategy to enum
        strategy_map = {
            'last_write_wins': ConflictResolutionStrategy.LAST_WRITE_WINS,
            'manual': ConflictResolutionStrategy.MANUAL,
            'merge': ConflictResolutionStrategy.MERGE,
            'source_wins': ConflictResolutionStrategy.SOURCE_WINS,
            'target_wins': ConflictResolutionStrategy.TARGET_WINS
        }
        
        strategy_enum = strategy_map.get(strategy, ConflictResolutionStrategy.LAST_WRITE_WINS)
        
        # Create a proper resolution entry for history tracking
        conflict_id = hashlib.md5(f"{field}_{source_value}_{target_value}_{strategy}".encode()).hexdigest()
        
        if strategy == 'last_write_wins':
            result = source_value
        elif strategy == 'manual' and user_choice:
            result = user_choice
        elif strategy == 'merge':
            result = f"{source_value} / {target_value}"
        else:
            result = source_value
        
        # Add to resolution history for compatibility
        resolution = ConflictResolution(
            conflict_id=conflict_id,
            resolution_strategy=strategy_enum,
            resolved_data={field: result},
            resolution_timestamp=datetime.now(),
            user_decision=(strategy == 'manual'),
            confidence_score=1.0 if strategy != 'manual' else 0.0
        )
        
        self.resolution_history.append(resolution)
        
        return result
    
    def get_conflict_history(self) -> List[Dict[str, Any]]:
        """Legacy method for backward compatibility"""
        return [{'strategy': res.resolution_strategy.value} for res in self.resolution_history]
    
    def _normalize_value(self, value: Any) -> Any:
        if isinstance(value, str):
            return value.strip().lower()
        return value
    
    def _merge_values(self, source_value: Any, target_value: Any) -> Any:
        if isinstance(source_value, str) and isinstance(target_value, str):
            return source_value if len(source_value) > len(target_value) else target_value
        return source_value


class ChangeTracker:
    """Tracks changes between source and target data"""
    
    def track_changes(self, source_data: Dict[str, Any], target_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        changes = []
        all_keys = set(source_data.keys()) | set(target_data.keys())
        
        for key in all_keys:
            source_value = source_data.get(key)
            target_value = target_data.get(key)
            
            if source_value != target_value:
                changes.append({
                    'field': key,
                    'source_value': source_value,
                    'target_value': target_value,
                    'timestamp': datetime.now()
                })
        
        return changes


class ConflictDetector:
    """Detects conflicts in synchronized data"""
    
    def detect_conflicts(self, changes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        conflicts = []
        
        for change in changes:
            if self._is_conflict(change):
                conflicts.append({
                    'change': change,
                    'type': self._determine_conflict_type(change),
                    'timestamp': datetime.now()
                })
        
        return conflicts
    
    def _is_conflict(self, change: Dict[str, Any]) -> bool:
        return True  # For now, consider all changes as potential conflicts
    
    def _determine_conflict_type(self, change: Dict[str, Any]) -> str:
        return 'data_mismatch'


class DataValidator:
    """Validates data integrity during sync, with checksums and consistency checks."""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.validation_rules = {
            'required_fields': ['id', 'name', 'email'],
            'email_format': r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        }
        self.checksums = {}

    def validate_data(self, data: Dict[str, Any]) -> bool:
        try:
            for field in self.validation_rules['required_fields']:
                if field not in data:
                    self.logger.error(f"Missing required field: {field}")
                    return False
            if 'email' in data and data['email']:
                if not re.match(self.validation_rules['email_format'], data['email']):
                    self.logger.error(f"Invalid email format: {data['email']}")
                    return False
            return True
        except Exception as e:
            self.logger.error(f"Validation error: {str(e)}")
            return False

    def generate_checksum(self, data: Dict[str, Any]) -> str:
        data_str = str(sorted(data.items()))
        checksum = hashlib.sha256(data_str.encode()).hexdigest()
        return checksum

    def verify_checksum(self, data: Dict[str, Any], checksum: str) -> bool:
        return self.generate_checksum(data) == checksum

    def check_consistency(self, data1: Dict[str, Any], data2: Dict[str, Any]) -> bool:
        return data1 == data2


class SyncMonitor:
    """
    Monitors synchronization operations and provides real-time status updates.
    """
    
    def __init__(self):
        self.metrics = {
            'sync_count': 0,
            'conflict_count': 0,
            'error_count': 0
        }
        self.logs = []
        self.active_operations = {}
    
    def start_operation(self, operation_id: str, operation_type: str):
        self.active_operations[operation_id] = {
            'type': operation_type,
            'start_time': datetime.now(),
            'status': 'running'
        }
    
    def complete_operation(self, operation_id: str, success: bool = True):
        if operation_id in self.active_operations:
            operation = self.active_operations[operation_id]
            operation['end_time'] = datetime.now()
            operation['status'] = 'completed' if success else 'failed'
            operation['duration'] = (operation['end_time'] - operation['start_time']).total_seconds()
            if success:
                self.metrics['sync_count'] += 1
            else:
                self.metrics['error_count'] += 1
    
    def log_event(self, message: str, level: str = 'info'):
        self.logs.append({
            'timestamp': datetime.now(),
            'message': message,
            'level': level
        })
    
    def get_metrics(self) -> Dict[str, Any]:
        return self.metrics.copy()
    
    def get_recent_logs(self, count: int = 50) -> List[Dict[str, Any]]:
        return self.logs[-count:] if self.logs else []
    
    def get_logs(self) -> List[Dict[str, Any]]:
        """Alias for get_recent_logs for backward compatibility"""
        return self.get_recent_logs()
    
    # Legacy methods for backward compatibility
    def track_sync(self, sync_type: str, data: Dict[str, Any]):
        self.metrics['sync_count'] += 1
        self.log_event(f"Sync tracked: {sync_type}")
    
    def track_conflict(self, conflict_data: Dict[str, Any]):
        self.metrics['conflict_count'] += 1
        self.log_event(f"Conflict tracked: {conflict_data}")
    
    def track_error(self, error_message: str):
        self.metrics['error_count'] += 1
        self.log_event(f"Error tracked: {error_message}", level='error')


class SyncEngine:
    """
    Advanced synchronization engine with comprehensive features.
    """
    
    def __init__(self, database_path: str = "sync_engine.db"):
        self.database_path = database_path
        self.connection = None
        self.logger = logging.getLogger(__name__)
        
        # Initialize all components
        self.conflict_resolver = ConflictResolver()
        self.recovery_manager = RecoveryManager()
        self.change_tracker = ChangeTracker()
        self.conflict_detector = ConflictDetector()
        self.validator = DataValidator()
        self.monitor = SyncMonitor()
        self.sync_state = {}  # In-memory state tracking
        
        self.current_session_id = None
        self.metrics = None
        self._progress_callbacks: List[Callable] = []
        self._status_callbacks: List[Callable] = []
        
        # Initialize database
        self._initialize_database()
    
    def _initialize_database(self):
        try:
            self.connection = sqlite3.connect(self.database_path, check_same_thread=False)
            self.connection.row_factory = sqlite3.Row
            
            cursor = self.connection.cursor()
            
            # Create tables (simplified for this version)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS sync_records (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    source_id TEXT NOT NULL,
                    target_id TEXT,
                    record_type TEXT NOT NULL,
                    data TEXT NOT NULL,
                    checksum TEXT NOT NULL,
                    last_modified TEXT NOT NULL,
                    sync_status TEXT NOT NULL,
                    conflict_data TEXT,
                    retry_count INTEGER DEFAULT 0,
                    error_message TEXT,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            self.connection.commit()
            
        except Exception as e:
            self.logger.error(f"Failed to initialize sync database: {e}")
            raise DatabaseException(f"Sync database initialization failed: {e}")
    
    def sync_data(self, source_data: Dict[str, Any], target_data: Dict[str, Any], 
                  strategy='last_write_wins', manual_choices=None) -> Tuple[Dict[str, Any], Dict[str, Any], List[Dict[str, Any]]]:
        """
        Synchronize data between source and target.
        """
        # Track changes
        changes = self.change_tracker.track_changes(source_data, target_data)
        
        # Detect conflicts
        conflicts = self.conflict_detector.detect_conflicts(changes)
        
        # Resolve conflicts
        manual_choices = manual_choices or {}
        for conflict in conflicts:
            field = conflict['change']['field']
            if strategy == 'manual':
                user_choice = manual_choices.get(field)
                resolved_value = self.conflict_resolver.resolve_conflict(
                    field, conflict['change']['source_value'], 
                    conflict['change']['target_value'], ConflictResolutionStrategy.MANUAL)
            else:
                strategy_enum = ConflictResolutionStrategy(strategy) if strategy in [s.value for s in ConflictResolutionStrategy] else ConflictResolutionStrategy.LAST_WRITE_WINS
                resolved_value = self.conflict_resolver.resolve_conflict(
                    field, conflict['change']['source_value'], 
                    conflict['change']['target_value'], strategy_enum)
            
            target_data[field] = resolved_value.resolved_data[field]
            self.monitor.track_conflict(conflict)
        
        # Validate
        valid_source = self.validator.validate_data(source_data)
        valid_target = self.validator.validate_data(target_data)
        if not (valid_source and valid_target):
            self.logger.error("Validation failed during sync.")
            self.monitor.track_error("Validation failed")
        
        # Update sync state
        self._update_sync_state(source_data, target_data)
        self.monitor.track_sync('sync', {'source': source_data.get('id'), 'target': target_data.get('id')})
        
        return source_data, target_data, conflicts
    
    def _update_sync_state(self, source_data: Dict[str, Any], target_data: Dict[str, Any]):
        item_id = source_data.get('id') or target_data.get('id')
        if not item_id:
            return
        
        source_hash = self._generate_hash(source_data)
        target_hash = self._generate_hash(target_data)
        
        self.sync_state[item_id] = {
            'item_id': item_id,
            'source_hash': source_hash,
            'target_hash': target_hash,
            'last_sync': datetime.now(),
            'status': 'synced'
        }
    
    def _generate_hash(self, data: Dict[str, Any]) -> str:
        data_str = str(sorted(data.items()))
        return hashlib.sha256(data_str.encode()).hexdigest()
    
    def get_sync_status(self, item_id: str) -> Optional[Dict[str, Any]]:
        return self.sync_state.get(item_id)
    
    def get_all_sync_states(self) -> List[Dict[str, Any]]:
        return list(self.sync_state.values())

    def recover_sync(self, item_id: str) -> bool:
        state = self.sync_state.get(item_id)
        if not state:
            self.logger.error(f"No sync state found for {item_id}")
            return False
        self.logger.info(f"Recovered sync for {item_id} to state at {state['last_sync']}")
        return True


class SyncDashboard:
    """
    Dashboard for displaying sync monitoring information.
    """
    
    def __init__(self, monitor: SyncMonitor):
        self.monitor = monitor
    
    def display_metrics(self):
        metrics = self.monitor.get_metrics()
        logger.info("üìä Sync Metrics:")
        for key, value in metrics.items():
            logger.debug("   {key}: {value}")
    
    def display_logs(self):
        logs = self.monitor.get_recent_logs(10)
        logger.debug("üìù Recent Sync Logs:")
        for log in logs:
            timestamp = log['timestamp'].strftime('%H:%M:%S')
            logger.debug("   [{timestamp}] {log['level'].upper()}: {log['message']}")


